# Lab 39: Introduction to Ensemble Methods (Bagging, Boosting)

## Overview
This lab demonstrates **Ensemble Learning**, specifically:
- Bagging (Random Forest)
- Boosting (Gradient Boosting)
- Comparison with a single Decision Tree

## Steps Performed
1. Trained a **Decision Tree** baseline model.
2. Trained a **Random Forest Classifier** using Bagging.
3. Trained a **Gradient Boosting Classifier**.
4. Compared their performance metrics.

## Layman's Explanation
Imagine asking **one person** (Decision Tree) vs asking **a team of people who vote** (Random Forest), or asking **a sequence of people where each one improves the mistakes of the previous** (Gradient Boosting).  
Ensemble methods generally improve accuracy because they combine strengths and reduce weaknesses.

## Issues & Fixes
- **LF/CRLF warnings** → handled by configuring `.gitattributes` or Git auto-conversion.
- **Package mismatches** were resolved by reinstalling compatible versions via pip.
- **Repeated run issue in Alnafi cloud labs** → noted as an inherent lab environment quirk.

## Screenshot
See `screenshot.png` for output of the lab run.

