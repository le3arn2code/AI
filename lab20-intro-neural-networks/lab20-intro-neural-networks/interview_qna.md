# Interview Q&A: Neural Networks

1. **Q:** What is a neuron in a neural network?  
   **A:** A mathematical function combining inputs and weights, passed through an activation function.

2. **Q:** Why do we need activation functions?  
   **A:** They introduce non-linearity, enabling networks to learn complex patterns.

3. **Q:** What is the difference between Sigmoid and ReLU?  
   **A:** Sigmoid outputs between 0 and 1, ReLU outputs 0 or the input directly.

4. **Q:** What is an input layer?  
   **A:** The first layer that receives raw data.

5. **Q:** What are hidden layers?  
   **A:** Intermediate layers where the model learns representations.

6. **Q:** What is the output layer?  
   **A:** The final layer that provides predictions.

7. **Q:** Why is ReLU preferred in deep networks?  
   **A:** It avoids vanishing gradients and speeds up convergence.

8. **Q:** What is the role of weights in a neuron?  
   **A:** They determine the importance of each input.

9. **Q:** What does it mean when we say neural networks are "universal function approximators"?  
   **A:** Given enough neurons/layers, they can approximate any mathematical function.

10. **Q:** What is overfitting in neural networks?  
    **A:** When a model learns noise instead of general patterns, reducing performance on unseen data.
